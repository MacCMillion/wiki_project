{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle \n",
    "import os\n",
    "import re\n",
    "import inspect\n",
    "\n",
    "from collections import defaultdict\n",
    "from functools import  partial\n",
    "from itertools import  chain\n",
    "from dataclasses import dataclass\n",
    "\n",
    "print(pd.__version__)\n",
    "\n",
    "VERBOSE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Nominations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo\n",
    "1. more than 1000 articles in duplicates?\n",
    "2. Check warum die alten Archive auch geparst werden\n",
    "\n",
    "Visualisierungen\n",
    "1. Multinominierung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load ends, transform it to a DataFrame and keep a set of all article names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['idx', 'title', 'dates'], dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ends.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Summarize clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates:\n",
      "multiple nominations: 1845\n",
      "number of nominations:                 4966 \n",
      "artilcles in ends:                10850\n",
      "unique articles in nominations:       3885 \n",
      "articles in merged data Frame:            4886\n"
     ]
    }
   ],
   "source": [
    "# Load results of parsing monthly archives\n",
    "df_FAC = pd.read_csv('./data/FAC_nomination.csv', sep=';', index_col=0, parse_dates=['nomination', 'last_comment'])  \n",
    "df_FAC = df_FAC[(np.datetime64('2005')<=df_FAC.nomination) & (df_FAC.nomination<=np.datetime64('2016'))]\n",
    "\n",
    "\n",
    "# Load results of parsing revision history \n",
    "with open('./res/article_dict.pkl', 'rb') as file:\n",
    "    ends_dict = pickle.load(file)\n",
    "    \n",
    "# convert revision histotory from dictionary to pd.DataFrame\n",
    "df_ends = [[i, article, dates]for i, (article, dates) in enumerate(ends_dict.items())]\n",
    "df_ends = pd.DataFrame(df_ends, columns=['idx', 'title', 'dates'])\n",
    "\n",
    "# pd.DataFrame with min/max date\n",
    "df_ends_min = [[i, article, max(dates), min(dates)] for i, (article, dates) in enumerate(ends_dict.items())]\n",
    "df_ends_min = pd.DataFrame(df_ends_min, columns=['idx', 'title', 'first', 'last'])\n",
    "\n",
    "# clean article names (min-version)\n",
    "# it's possible to increase  number of matching articles, by preprocessing\n",
    "df_FAC['title'] = df_FAC.title.str.replace('/archive\\d', '') # These are actually unique nominations\n",
    "df_ends['title'] = df_ends.title.str.replace('/archive\\d', '') # These likely not\n",
    "df_ends_min['title'] = df_ends_min.title.str.replace('/archive\\d', '')\n",
    "\n",
    "# This will produce duplicates,\n",
    "#   1) append all dates\n",
    "df_ends['dates'] = df_ends.groupby('title').agg({'dates' :'sum'})\n",
    "#df_ends.reset_index(inplace=True)\n",
    "\n",
    "##  2) chose min, max\n",
    "agg_funcs = {'first': 'min', \n",
    "             'last' : 'max'}\n",
    "df_ends_min = df_ends_min.groupby('title').agg(agg_funcs)\n",
    "\n",
    "\n",
    "n_FAC = len(df_FAC)\n",
    "n_ends = len(df_ends)\n",
    "\n",
    "# We only keep the first nomination (simplification)\n",
    "df_FAC['has_duplicate'] = df_FAC.duplicated(subset='title', keep=False)\n",
    "print('duplicates:')\n",
    "print(f'multiple nominations: {sum(df_FAC.has_duplicate)}')\n",
    "df_FAC = df_FAC.loc[~df_FAC.sort_values('nomination').duplicated(subset='title', keep='first'),]\n",
    "\n",
    "# merge\n",
    "df_merge = pd.merge(df_FAC, df_ends, on='title')\n",
    "n_FAC_nd = len(df_FAC)\n",
    "print(f'number of nominations: {n_FAC:>20} \\nartilcles in ends: {n_ends:>20}'\n",
    "      f'\\nunique articles in nominations: {n_FAC_nd:10} '\n",
    "      f'\\narticles in merged data Frame: {len(df_merge):15}')\n",
    "\n",
    "df_FAC.to_csv('./tmp/FAC_merge.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Decide End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx                       int64\n",
      "title                    object\n",
      "nomination       datetime64[ns]\n",
      "last_comment     datetime64[ns]\n",
      "has_duplicate              bool\n",
      "dtype: object\n",
      "3773 9645\n",
      "No date (< 2W) found for article: Taylor Swift\n",
      "No date (< 2W) found for article: Jack Parsons (rocket engineer)\n",
      "No date (< 2W) found for article: Potential cultural impact of extraterrestrial contact\n",
      "No date (< 2W) found for article: Fluorine\n",
      "No date (< 2W) found for article: Ashley Tisdale\n",
      "No date (< 2W) found for article: Borat: Cultural Learnings of America for Make Benefit Glorious Nation of Kazakhstan\n",
      "No date (< 2W) found for article: iPod\n",
      "No date (< 2W) found for article: Pixies (band)\n",
      "No date (< 2W) found for article: West Bengal\n",
      "No date (< 2W) found for article: Paul Martin\n",
      "No date (< 2W) found for article: Stanley Kubrick\n",
      "No date (< 2W) found for article: Moncton\n",
      "No date (< 2W) found for article: Freemasonry\n",
      "No date (< 2W) found for article: Stonewall riots\n",
      "No date (< 2W) found for article: Earth\n",
      "No date (< 2W) found for article: Funeral of Pope John Paul II\n",
      "No date (< 2W) found for article: Mars\n",
      "No date (< 2W) found for article: Xanadu House\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('2005-01-14T15:26:07.000000')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "with open('./res/article_dict.pkl', 'rb') as file:\n",
    "    ends_dict = pickle.load(file)\n",
    "\n",
    "# Set up dict {article : np.array[1, len(dates)]}df_FAC = pd.read_csv('./tmp/FAC_merge.csv', sep=';', parse_dates=[3,4], index_col=0)\n",
    "res = defaultdict(list)\n",
    "for article, dates in ends_dict.items():\n",
    "    article = re.sub('/archive\\d', '', article)\n",
    "    dates = np.array([np.datetime64(date) for date in dates])\n",
    "    res[article].append(dates)\n",
    "ends_dict = res\n",
    "\n",
    "# get set of titles\n",
    "art_set = set(ends_dict.keys())\n",
    "\n",
    "# read df_FAC (post I.)\n",
    "\n",
    "df_FAC = df_FAC.loc[df_FAC.title.isin(art_set),]\n",
    "print(df_FAC.dtypes)\n",
    "\n",
    "# convert pd.DataFrame to \n",
    "FAC_dict = {k: np.datetime64(v) for k,v in df_FAC[['title', 'last_comment']].values}\n",
    "print(len(FAC_dict), len(ends_dict))\n",
    "\n",
    "new_dict = {}\n",
    "count =0\n",
    "for article, last_date in FAC_dict.items():\n",
    "    two_weeks_later = last_date + np.timedelta64(2, 'W')\n",
    "    dates = list(chain.from_iterable(ends_dict[article]))   # just to be sure list is falttened\n",
    "    dates = [date for date in dates if date < two_weeks_later]\n",
    "    # print(two_weeks_later, type(dates), type(dates[0]), type(two_weeks_later))\n",
    "    #new_date = np.max(dates) if dates else last_date        \n",
    "    if dates:\n",
    "        new_date  = max(dates)\n",
    "    else:\n",
    "        new_date = last_date\n",
    "        print(f'No date (< 2W) found for article: {article}')\n",
    "    new_dict[article] = new_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FAC_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for article, dates in art_dict.items():\n",
    "    dates = np.array([np.datetime64(date) for date in dates])\n",
    "    print(f'min:{min(dates)} max:{max(dates)}')\n",
    "    p1 = dates[(dates- dates[0]) > np.timedelta64(30, 'D')]\n",
    "    p2 = dates[~((dates- dates[0]) > np.timedelta64(30, 'D'))]\n",
    "    print(article)\n",
    "    print(len(p1), len(p2))\n",
    "    if i >= 1:\n",
    "        break\n",
    "    i+=1\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(res['Belgium national football team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FAC = pd.read_csv('./data/FAC_nomination.csv', sep=';', index_col=0, parse_dates=['nomination', 'last_comment'])  \n",
    "d = df_FAC.groupby('title').count().sort_values('idx')\n",
    "len(d.loc[d.idx >= 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Same-sex marriage</td>\n",
       "      <td>{2003-09-01 00:17:27, 2003-10-02 06:17:00, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MKULTRA</td>\n",
       "      <td>{2003-09-01 00:17:27, 2003-10-02 06:17:00, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Aztalan State Park</td>\n",
       "      <td>{2003-09-01 00:17:27, 2003-10-02 06:17:00, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Provinces of Thailand</td>\n",
       "      <td>{2003-11-30 10:39:40, 2003-10-15 01:15:15, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Lawrence v. Texas</td>\n",
       "      <td>{2003-10-15 01:15:15, 2003-09-01 00:17:27, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Damascus steel</td>\n",
       "      <td>{2003-09-28 06:00:19, 2003-08-28 23:53:05, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>White Rose</td>\n",
       "      <td>{2003-09-28 06:00:19, 2003-08-28 23:53:05, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Chariot racing</td>\n",
       "      <td>{2003-09-28 06:00:19, 2003-08-28 23:53:05, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Schizophrenia</td>\n",
       "      <td>{2005-02-12 17:40:04, 2005-02-24 18:11:06, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Beach Cricket</td>\n",
       "      <td>{2003-08-04 06:59:33}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Beach cricket</td>\n",
       "      <td>{2003-10-15 01:15:15, 2003-09-01 00:17:27, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Richard Wagner</td>\n",
       "      <td>{2004-01-06 23:43:35, 2003-12-22 16:59:53, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Command-Query Separation</td>\n",
       "      <td>{2004-01-06 23:43:35, 2003-12-22 16:59:53, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Illegal Prime</td>\n",
       "      <td>{2003-08-09 21:05:24}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Illegal prime</td>\n",
       "      <td>{2003-09-28 06:00:19, 2003-08-28 23:53:05, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Basic taste</td>\n",
       "      <td>{2003-10-15 01:15:15, 2003-09-01 00:17:27, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Revised Standard Version</td>\n",
       "      <td>{2003-11-30 10:39:40, 2003-10-15 01:15:15, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>History of the United States</td>\n",
       "      <td>{2004-01-06 23:43:35, 2003-12-22 16:59:53, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Non-Indo-European roots of Germanic languages</td>\n",
       "      <td>{2003-09-28 06:00:19, 2003-09-07 07:28:57, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Not the Nine O'Clock News</td>\n",
       "      <td>{2003-12-15 14:54:46, 2003-11-30 10:39:40, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Alliterative verse</td>\n",
       "      <td>{2003-10-15 01:15:15, 2003-11-27 13:56:37, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>Taiwanese language</td>\n",
       "      <td>{2003-10-12 16:10:12, 2003-10-24 23:00:30, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>Bible code</td>\n",
       "      <td>{2003-10-12 16:10:12, 2003-10-24 23:00:30, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>Pattern welding</td>\n",
       "      <td>{2003-10-12 16:10:12, 2003-10-24 23:00:30, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Phonograph cylinder</td>\n",
       "      <td>{2003-11-30 10:39:40, 2003-10-15 01:15:15, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>Dictionary</td>\n",
       "      <td>{2004-01-06 23:43:35, 2003-12-22 16:59:53, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Japan</td>\n",
       "      <td>{2007-04-09 18:21:33, 2004-01-06 23:43:35, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>Marcus Antonius</td>\n",
       "      <td>{2003-11-27 13:56:37, 2003-10-31 06:05:10, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>Io (moon)</td>\n",
       "      <td>{2007-07-29 17:37:54, 2003-11-27 13:56:37, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Holy Prepuce</td>\n",
       "      <td>{2003-11-20 04:27:26, 2003-11-04 03:09:53, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10820</th>\n",
       "      <td>10820</td>\n",
       "      <td>2003 Cricket World Cup Final/archive1</td>\n",
       "      <td>{2017-01-15 23:54:44, 2016-12-30 18:22:31, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10821</th>\n",
       "      <td>10821</td>\n",
       "      <td>Millard Fillmore/archive1</td>\n",
       "      <td>{2017-01-15 23:54:44, 2017-01-05 19:59:46, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10822</th>\n",
       "      <td>10822</td>\n",
       "      <td>Russell family (Passions)/archive1</td>\n",
       "      <td>{2017-01-15 23:54:44, 2017-01-05 19:59:46, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10823</th>\n",
       "      <td>10823</td>\n",
       "      <td>King Kalākaua's world tour/archive1</td>\n",
       "      <td>{2017-01-15 23:54:44, 2017-01-05 19:59:46, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10824</th>\n",
       "      <td>10824</td>\n",
       "      <td>True Detective (season 1)/archive6</td>\n",
       "      <td>{2017-01-15 23:54:44, 2017-01-05 19:59:46, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10825</th>\n",
       "      <td>10825</td>\n",
       "      <td>Crispy Gamer/archive1</td>\n",
       "      <td>{2017-01-02 01:11:08}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10826</th>\n",
       "      <td>10826</td>\n",
       "      <td>Joker (comics)/archive2</td>\n",
       "      <td>{2017-01-15 23:54:44, 2017-01-05 19:59:46, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10827</th>\n",
       "      <td>10827</td>\n",
       "      <td>Acne vulgaris/archive2</td>\n",
       "      <td>{2017-01-15 23:54:44, 2017-01-05 19:59:46, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10828</th>\n",
       "      <td>10828</td>\n",
       "      <td>CMLL World Heavyweight Championship/archive2</td>\n",
       "      <td>{2017-01-15 23:54:44, 2017-01-05 19:59:46, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10829</th>\n",
       "      <td>10829</td>\n",
       "      <td>Beta-Hydroxy beta-methylbutyric acid/archive3</td>\n",
       "      <td>{2017-01-15 23:54:44, 2017-01-05 19:59:46, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10830</th>\n",
       "      <td>10830</td>\n",
       "      <td>The Winds of Winter (Game of Thrones)/archive1</td>\n",
       "      <td>{2017-01-15 23:54:44, 2017-01-05 19:59:46, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10831</th>\n",
       "      <td>10831</td>\n",
       "      <td>Nyuserre Ini/archive1</td>\n",
       "      <td>{2017-01-15 23:54:44, 2017-01-05 19:59:46, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10832</th>\n",
       "      <td>10832</td>\n",
       "      <td>Red wattlebird/archive1</td>\n",
       "      <td>{2017-01-15 23:54:44, 2017-01-09 10:00:42, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10833</th>\n",
       "      <td>10833</td>\n",
       "      <td>Red-throated loon/archive1</td>\n",
       "      <td>{2017-01-15 23:54:44, 2017-01-09 10:00:42, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10834</th>\n",
       "      <td>10834</td>\n",
       "      <td>Ninety-five Theses/archive1</td>\n",
       "      <td>{2017-01-15 23:54:44, 2017-01-09 10:00:42, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10835</th>\n",
       "      <td>10835</td>\n",
       "      <td>Zenobia/archive1</td>\n",
       "      <td>{2017-01-15 23:54:44, 2017-01-09 10:00:42, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10836</th>\n",
       "      <td>10836</td>\n",
       "      <td>Star of Bengal/archive1</td>\n",
       "      <td>{2017-01-15 23:54:44, 2017-01-09 10:00:42, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10837</th>\n",
       "      <td>10837</td>\n",
       "      <td>Siege of Melos/archive1</td>\n",
       "      <td>{2017-01-09 10:00:42}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10838</th>\n",
       "      <td>10838</td>\n",
       "      <td>Joe Biden/archive1</td>\n",
       "      <td>{2017-01-13 05:11:47}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10839</th>\n",
       "      <td>10839</td>\n",
       "      <td>Louis Leblanc/archive1</td>\n",
       "      <td>{2017-01-13 23:08:05, 2017-01-18 11:16:22, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10840</th>\n",
       "      <td>10840</td>\n",
       "      <td>House of Music/archive2</td>\n",
       "      <td>{2017-01-13 23:08:05, 2017-01-18 11:16:22, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10841</th>\n",
       "      <td>10841</td>\n",
       "      <td>Siberian accentor/archive1</td>\n",
       "      <td>{2017-01-18 11:16:22, 2017-01-16 02:17:55, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10842</th>\n",
       "      <td>10842</td>\n",
       "      <td>John C. Calhoun/archive2</td>\n",
       "      <td>{2017-01-16 12:38:35, 2017-01-16 20:27:01, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10843</th>\n",
       "      <td>10843</td>\n",
       "      <td>Siege of Arrah/archive1</td>\n",
       "      <td>{2017-01-16 12:38:35, 2017-01-16 20:27:01, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10844</th>\n",
       "      <td>10844</td>\n",
       "      <td>Virgin and Child Enthroned (van der Weyden)/ar...</td>\n",
       "      <td>{2017-01-16 12:38:35, 2017-01-16 20:27:01, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10845</th>\n",
       "      <td>10845</td>\n",
       "      <td>Iazyges/archive1</td>\n",
       "      <td>{2017-01-16 12:38:35, 2017-01-16 20:27:01, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10846</th>\n",
       "      <td>10846</td>\n",
       "      <td>Economy of Iran/archive4</td>\n",
       "      <td>{2017-01-16 12:38:35, 2017-01-16 20:27:01, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10847</th>\n",
       "      <td>10847</td>\n",
       "      <td>History of US science fiction and fantasy maga...</td>\n",
       "      <td>{2017-01-16 12:38:35, 2017-01-16 20:27:01, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10848</th>\n",
       "      <td>10848</td>\n",
       "      <td>August Meyszner/archive1</td>\n",
       "      <td>{2017-01-17 05:11:49, 2017-01-18 11:16:22, 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10849</th>\n",
       "      <td>10849</td>\n",
       "      <td>Sarawak/archive2</td>\n",
       "      <td>{2017-01-18 11:16:22}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10850 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                                                  1  \\\n",
       "0          0                                  Same-sex marriage   \n",
       "1          1                                            MKULTRA   \n",
       "2          2                                 Aztalan State Park   \n",
       "3          3                              Provinces of Thailand   \n",
       "4          4                                  Lawrence v. Texas   \n",
       "5          5                                     Damascus steel   \n",
       "6          6                                         White Rose   \n",
       "7          7                                     Chariot racing   \n",
       "8          8                                      Schizophrenia   \n",
       "9          9                                      Beach Cricket   \n",
       "10        10                                      Beach cricket   \n",
       "11        11                                     Richard Wagner   \n",
       "12        12                           Command-Query Separation   \n",
       "13        13                                      Illegal Prime   \n",
       "14        14                                      Illegal prime   \n",
       "15        15                                        Basic taste   \n",
       "16        16                           Revised Standard Version   \n",
       "17        17                       History of the United States   \n",
       "18        18      Non-Indo-European roots of Germanic languages   \n",
       "19        19                          Not the Nine O'Clock News   \n",
       "20        20                                 Alliterative verse   \n",
       "21        21                                 Taiwanese language   \n",
       "22        22                                         Bible code   \n",
       "23        23                                    Pattern welding   \n",
       "24        24                                Phonograph cylinder   \n",
       "25        25                                         Dictionary   \n",
       "26        26                                              Japan   \n",
       "27        27                                    Marcus Antonius   \n",
       "28        28                                          Io (moon)   \n",
       "29        29                                       Holy Prepuce   \n",
       "...      ...                                                ...   \n",
       "10820  10820              2003 Cricket World Cup Final/archive1   \n",
       "10821  10821                          Millard Fillmore/archive1   \n",
       "10822  10822                 Russell family (Passions)/archive1   \n",
       "10823  10823                King Kalākaua's world tour/archive1   \n",
       "10824  10824                 True Detective (season 1)/archive6   \n",
       "10825  10825                              Crispy Gamer/archive1   \n",
       "10826  10826                            Joker (comics)/archive2   \n",
       "10827  10827                             Acne vulgaris/archive2   \n",
       "10828  10828       CMLL World Heavyweight Championship/archive2   \n",
       "10829  10829      Beta-Hydroxy beta-methylbutyric acid/archive3   \n",
       "10830  10830     The Winds of Winter (Game of Thrones)/archive1   \n",
       "10831  10831                              Nyuserre Ini/archive1   \n",
       "10832  10832                            Red wattlebird/archive1   \n",
       "10833  10833                         Red-throated loon/archive1   \n",
       "10834  10834                        Ninety-five Theses/archive1   \n",
       "10835  10835                                   Zenobia/archive1   \n",
       "10836  10836                            Star of Bengal/archive1   \n",
       "10837  10837                            Siege of Melos/archive1   \n",
       "10838  10838                                 Joe Biden/archive1   \n",
       "10839  10839                             Louis Leblanc/archive1   \n",
       "10840  10840                            House of Music/archive2   \n",
       "10841  10841                         Siberian accentor/archive1   \n",
       "10842  10842                           John C. Calhoun/archive2   \n",
       "10843  10843                            Siege of Arrah/archive1   \n",
       "10844  10844  Virgin and Child Enthroned (van der Weyden)/ar...   \n",
       "10845  10845                                   Iazyges/archive1   \n",
       "10846  10846                           Economy of Iran/archive4   \n",
       "10847  10847  History of US science fiction and fantasy maga...   \n",
       "10848  10848                           August Meyszner/archive1   \n",
       "10849  10849                                   Sarawak/archive2   \n",
       "\n",
       "                                                       2  \n",
       "0      {2003-09-01 00:17:27, 2003-10-02 06:17:00, 200...  \n",
       "1      {2003-09-01 00:17:27, 2003-10-02 06:17:00, 200...  \n",
       "2      {2003-09-01 00:17:27, 2003-10-02 06:17:00, 200...  \n",
       "3      {2003-11-30 10:39:40, 2003-10-15 01:15:15, 200...  \n",
       "4      {2003-10-15 01:15:15, 2003-09-01 00:17:27, 200...  \n",
       "5      {2003-09-28 06:00:19, 2003-08-28 23:53:05, 200...  \n",
       "6      {2003-09-28 06:00:19, 2003-08-28 23:53:05, 200...  \n",
       "7      {2003-09-28 06:00:19, 2003-08-28 23:53:05, 200...  \n",
       "8      {2005-02-12 17:40:04, 2005-02-24 18:11:06, 200...  \n",
       "9                                  {2003-08-04 06:59:33}  \n",
       "10     {2003-10-15 01:15:15, 2003-09-01 00:17:27, 200...  \n",
       "11     {2004-01-06 23:43:35, 2003-12-22 16:59:53, 200...  \n",
       "12     {2004-01-06 23:43:35, 2003-12-22 16:59:53, 200...  \n",
       "13                                 {2003-08-09 21:05:24}  \n",
       "14     {2003-09-28 06:00:19, 2003-08-28 23:53:05, 200...  \n",
       "15     {2003-10-15 01:15:15, 2003-09-01 00:17:27, 200...  \n",
       "16     {2003-11-30 10:39:40, 2003-10-15 01:15:15, 200...  \n",
       "17     {2004-01-06 23:43:35, 2003-12-22 16:59:53, 200...  \n",
       "18     {2003-09-28 06:00:19, 2003-09-07 07:28:57, 200...  \n",
       "19     {2003-12-15 14:54:46, 2003-11-30 10:39:40, 200...  \n",
       "20     {2003-10-15 01:15:15, 2003-11-27 13:56:37, 200...  \n",
       "21     {2003-10-12 16:10:12, 2003-10-24 23:00:30, 200...  \n",
       "22     {2003-10-12 16:10:12, 2003-10-24 23:00:30, 200...  \n",
       "23     {2003-10-12 16:10:12, 2003-10-24 23:00:30, 200...  \n",
       "24     {2003-11-30 10:39:40, 2003-10-15 01:15:15, 200...  \n",
       "25     {2004-01-06 23:43:35, 2003-12-22 16:59:53, 200...  \n",
       "26     {2007-04-09 18:21:33, 2004-01-06 23:43:35, 200...  \n",
       "27     {2003-11-27 13:56:37, 2003-10-31 06:05:10, 200...  \n",
       "28     {2007-07-29 17:37:54, 2003-11-27 13:56:37, 200...  \n",
       "29     {2003-11-20 04:27:26, 2003-11-04 03:09:53, 200...  \n",
       "...                                                  ...  \n",
       "10820  {2017-01-15 23:54:44, 2016-12-30 18:22:31, 201...  \n",
       "10821  {2017-01-15 23:54:44, 2017-01-05 19:59:46, 201...  \n",
       "10822  {2017-01-15 23:54:44, 2017-01-05 19:59:46, 201...  \n",
       "10823  {2017-01-15 23:54:44, 2017-01-05 19:59:46, 201...  \n",
       "10824  {2017-01-15 23:54:44, 2017-01-05 19:59:46, 201...  \n",
       "10825                              {2017-01-02 01:11:08}  \n",
       "10826  {2017-01-15 23:54:44, 2017-01-05 19:59:46, 201...  \n",
       "10827  {2017-01-15 23:54:44, 2017-01-05 19:59:46, 201...  \n",
       "10828  {2017-01-15 23:54:44, 2017-01-05 19:59:46, 201...  \n",
       "10829  {2017-01-15 23:54:44, 2017-01-05 19:59:46, 201...  \n",
       "10830  {2017-01-15 23:54:44, 2017-01-05 19:59:46, 201...  \n",
       "10831  {2017-01-15 23:54:44, 2017-01-05 19:59:46, 201...  \n",
       "10832  {2017-01-15 23:54:44, 2017-01-09 10:00:42, 201...  \n",
       "10833  {2017-01-15 23:54:44, 2017-01-09 10:00:42, 201...  \n",
       "10834  {2017-01-15 23:54:44, 2017-01-09 10:00:42, 201...  \n",
       "10835  {2017-01-15 23:54:44, 2017-01-09 10:00:42, 201...  \n",
       "10836  {2017-01-15 23:54:44, 2017-01-09 10:00:42, 201...  \n",
       "10837                              {2017-01-09 10:00:42}  \n",
       "10838                              {2017-01-13 05:11:47}  \n",
       "10839  {2017-01-13 23:08:05, 2017-01-18 11:16:22, 201...  \n",
       "10840  {2017-01-13 23:08:05, 2017-01-18 11:16:22, 201...  \n",
       "10841  {2017-01-18 11:16:22, 2017-01-16 02:17:55, 201...  \n",
       "10842  {2017-01-16 12:38:35, 2017-01-16 20:27:01, 201...  \n",
       "10843  {2017-01-16 12:38:35, 2017-01-16 20:27:01, 201...  \n",
       "10844  {2017-01-16 12:38:35, 2017-01-16 20:27:01, 201...  \n",
       "10845  {2017-01-16 12:38:35, 2017-01-16 20:27:01, 201...  \n",
       "10846  {2017-01-16 12:38:35, 2017-01-16 20:27:01, 201...  \n",
       "10847  {2017-01-16 12:38:35, 2017-01-16 20:27:01, 201...  \n",
       "10848  {2017-01-17 05:11:49, 2017-01-18 11:16:22, 201...  \n",
       "10849                              {2017-01-18 11:16:22}  \n",
       "\n",
       "[10850 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./res/article_dict.pkl', 'rb') as file:\n",
    "    ends_dict = pickle.load(file)\n",
    "    \n",
    "df_ends = [[i, article, set(dates)]for i, (article, dates) in enumerate(ends_dict.items())]\n",
    "df_ends = pd.DataFrame(df_ends)\n",
    "\n",
    "df_ends\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wikiproject)",
   "language": "python",
   "name": "wikiproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
