{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle \n",
    "import os\n",
    "import re\n",
    "import inspect\n",
    "from importlib import reload as irl\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import  chain\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "print(pd.__version__)\n",
    "\n",
    "VERBOSE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Nominations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ToDo\n",
    "1. more than 1000 articles in duplicates?\n",
    "\n",
    "Visualisierungen\n",
    "1. Multinominierung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load ends, transform it to a DataFrame and keep a set of all article names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Summarize and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates:\n",
      "multiple nominations: 1845\n",
      "number of nominations:                 4966 \n",
      "artilcles in ends:                10451\n",
      "unique articles in nominations:       3885 \n",
      "articles in merged data Frame:            3774\n"
     ]
    }
   ],
   "source": [
    "# Load results of parsing monthly archives\n",
    "df_FAC = pd.read_csv('./data/FAC_nomination.csv', sep=';', index_col=0, parse_dates=['nomination', 'last_comment'])  \n",
    "df_FAC = df_FAC[(np.datetime64('2005')<=df_FAC.nomination) & (df_FAC.nomination<=np.datetime64('2016'))]\n",
    "\n",
    "# Load results of parsing revision history \n",
    "with open('./data/FAC_ends.pkl', 'rb') as file:\n",
    "    ends_dict = pickle.load(file)\n",
    "    \n",
    "# convert revision histotory from dictionary to pd.DataFrame\n",
    "df_ends = [[i, article, dates]for i, (article, dates) in enumerate(ends_dict.items())]\n",
    "df_ends = pd.DataFrame(df_ends, columns=['idx', 'title', 'dates'])\n",
    "\n",
    "# pd.DataFrame with min/max date\n",
    "df_ends_min = [[i, article, max(dates), min(dates)] for i, (article, dates) in enumerate(ends_dict.items())]\n",
    "df_ends_min = pd.DataFrame(df_ends_min, columns=['idx', 'title', 'first', 'last'])\n",
    "\n",
    "# clean article names (min-version)\n",
    "# it's possible to increase  number of matching articles, by preprocessing\n",
    "df_FAC['title'] = df_FAC.title.str.replace('/archive\\d', '') # These are actually unique nominations\n",
    "df_ends['title'] = df_ends.title.str.replace('/archive\\d', '') # These likely not\n",
    "df_ends_min['title'] = df_ends_min.title.str.replace('/archive\\d', '')\n",
    "\n",
    "# This will produce duplicates,\n",
    "#   1) append all dates\n",
    "df_ends = df_ends.groupby('title').agg({'dates' :'sum'})\n",
    "#df_ends.reset_index(inplace=True)\n",
    "\n",
    "##  2) chose min, max\n",
    "agg_funcs = {'first': 'min', \n",
    "             'last' : 'max'}\n",
    "df_ends_min = df_ends_min.groupby('title').agg(agg_funcs)\n",
    "\n",
    "\n",
    "n_FAC = len(df_FAC)\n",
    "n_ends = len(df_ends)\n",
    "\n",
    "# We only keep the first nomination (simplification)\n",
    "df_FAC['has_duplicate'] = df_FAC.duplicated(subset='title', keep=False)\n",
    "print('duplicates:')\n",
    "print(f'multiple nominations: {sum(df_FAC.has_duplicate)}')\n",
    "df_FAC = df_FAC.loc[~df_FAC.sort_values('nomination').duplicated(subset='title', keep='first'),]\n",
    "\n",
    "# merge\n",
    "df_merge = pd.merge(df_FAC, df_ends, on='title')\n",
    "n_FAC_nd = len(df_FAC)\n",
    "print(f'number of nominations: {n_FAC:>20} \\nartilcles in ends: {n_ends:>20}'\n",
    "      f'\\nunique articles in nominations: {n_FAC_nd:10} '\n",
    "      f'\\narticles in merged data Frame: {len(df_merge):15}')\n",
    "\n",
    "df_merge.to_csv('./tmp/FAC_merge.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Decide End\n",
    "(Didn't manage to do this pandas so I went back to dictionaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3774\n",
      "3774\n",
      "3774 10451\n",
      "No date (< 2W) found for article: Adventure Time\n",
      "No date (< 2W) found for article: Taylor Swift\n",
      "No date (< 2W) found for article: Jack Parsons (rocket engineer)\n",
      "No date (< 2W) found for article: Potential cultural impact of extraterrestrial contact\n",
      "No date (< 2W) found for article: Fluorine\n",
      "No date (< 2W) found for article: Ashley Tisdale\n",
      "No date (< 2W) found for article: Borat: Cultural Learnings of America for Make Benefit Glorious Nation of Kazakhstan\n",
      "No date (< 2W) found for article: iPod\n",
      "No date (< 2W) found for article: Pixies (band)\n",
      "No date (< 2W) found for article: West Bengal\n",
      "No date (< 2W) found for article: Paul Martin\n",
      "No date (< 2W) found for article: Stanley Kubrick\n",
      "No date (< 2W) found for article: Moncton\n",
      "No date (< 2W) found for article: Freemasonry\n",
      "No date (< 2W) found for article: Stonewall riots\n",
      "No date (< 2W) found for article: Earth\n",
      "No date (< 2W) found for article: Funeral of Pope John Paul II\n",
      "No date (< 2W) found for article: Mars\n",
      "No date (< 2W) found for article: Xanadu House\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>title</th>\n",
       "      <th>nomination</th>\n",
       "      <th>last_comment</th>\n",
       "      <th>has_duplicate</th>\n",
       "      <th>dates</th>\n",
       "      <th>end_date_x</th>\n",
       "      <th>end_date_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>434</td>\n",
       "      <td>Belgium national football team</td>\n",
       "      <td>2015-11-21 10:28:00</td>\n",
       "      <td>2016-02-05 08:07:00</td>\n",
       "      <td>False</td>\n",
       "      <td>[2015-11-21 10:32:10, 2015-11-21 12:36:21, 201...</td>\n",
       "      <td>2016-02-05 08:56:59</td>\n",
       "      <td>2016-02-05 08:56:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>435</td>\n",
       "      <td>Bicycle kick</td>\n",
       "      <td>2015-12-27 04:23:00</td>\n",
       "      <td>2016-02-13 15:59:00</td>\n",
       "      <td>False</td>\n",
       "      <td>[2015-12-27 04:24:35, 2015-12-27 14:09:14, 201...</td>\n",
       "      <td>2016-02-13 14:47:32</td>\n",
       "      <td>2016-02-13 14:47:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>443</td>\n",
       "      <td>Mullum Malarum</td>\n",
       "      <td>2015-11-09 07:51:00</td>\n",
       "      <td>2016-02-06 19:41:00</td>\n",
       "      <td>False</td>\n",
       "      <td>[2015-11-09 07:49:01, 2015-11-09 09:00:07, 201...</td>\n",
       "      <td>2016-02-05 23:08:09</td>\n",
       "      <td>2016-02-05 23:08:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>449</td>\n",
       "      <td>2012 Gatorade Duels</td>\n",
       "      <td>2015-12-21 15:14:00</td>\n",
       "      <td>2016-01-29 22:10:00</td>\n",
       "      <td>False</td>\n",
       "      <td>[2015-12-21 15:15:45, 2015-12-23 15:58:09, 201...</td>\n",
       "      <td>2016-01-29 22:03:31</td>\n",
       "      <td>2016-01-29 22:03:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>450</td>\n",
       "      <td>Briarcliff Farms</td>\n",
       "      <td>2015-12-25 00:20:00</td>\n",
       "      <td>2016-01-29 22:22:00</td>\n",
       "      <td>False</td>\n",
       "      <td>[2015-12-25 00:25:15, 2015-12-25 23:08:08, 201...</td>\n",
       "      <td>2016-02-11 01:11:48</td>\n",
       "      <td>2016-02-11 01:11:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                           title          nomination  \\\n",
       "0  434  Belgium national football team 2015-11-21 10:28:00   \n",
       "1  435                    Bicycle kick 2015-12-27 04:23:00   \n",
       "2  443                  Mullum Malarum 2015-11-09 07:51:00   \n",
       "3  449             2012 Gatorade Duels 2015-12-21 15:14:00   \n",
       "4  450                Briarcliff Farms 2015-12-25 00:20:00   \n",
       "\n",
       "         last_comment  has_duplicate  \\\n",
       "0 2016-02-05 08:07:00          False   \n",
       "1 2016-02-13 15:59:00          False   \n",
       "2 2016-02-06 19:41:00          False   \n",
       "3 2016-01-29 22:10:00          False   \n",
       "4 2016-01-29 22:22:00          False   \n",
       "\n",
       "                                               dates          end_date_x  \\\n",
       "0  [2015-11-21 10:32:10, 2015-11-21 12:36:21, 201... 2016-02-05 08:56:59   \n",
       "1  [2015-12-27 04:24:35, 2015-12-27 14:09:14, 201... 2016-02-13 14:47:32   \n",
       "2  [2015-11-09 07:49:01, 2015-11-09 09:00:07, 201... 2016-02-05 23:08:09   \n",
       "3  [2015-12-21 15:15:45, 2015-12-23 15:58:09, 201... 2016-01-29 22:03:31   \n",
       "4  [2015-12-25 00:25:15, 2015-12-25 23:08:08, 201... 2016-02-11 01:11:48   \n",
       "\n",
       "           end_date_y  \n",
       "0 2016-02-05 08:56:59  \n",
       "1 2016-02-13 14:47:32  \n",
       "2 2016-02-05 23:08:09  \n",
       "3 2016-01-29 22:03:31  \n",
       "4 2016-02-11 01:11:48  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/FAC_ends.pkl', 'rb') as file:\n",
    "    ends_dict = pickle.load(file)\n",
    "\n",
    "res = defaultdict(list)\n",
    "for article, dates in ends_dict.items():\n",
    "    article = re.sub('/archive\\d', '', article)\n",
    "    dates = np.array([np.datetime64(date) for date in dates])\n",
    "    res[article].append(dates)\n",
    "ends_dict = res\n",
    "\n",
    "# get set of titles\n",
    "art_set = set(ends_dict.keys())\n",
    "\n",
    "# read df_FAC (post I.)\n",
    "print(len(df_merge))\n",
    "df_merge = df_merge.loc[df_merge.title.isin(art_set),]\n",
    "print(len(df_merge))\n",
    "\n",
    "# convert pd.DataFrame to dict\n",
    "FAC_dict = {k: np.datetime64(v) for k,v in df_merge[['title', 'last_comment']].values}\n",
    "print(len(FAC_dict), len(ends_dict))\n",
    "\n",
    "new_dict = {}\n",
    "count =0\n",
    "for article, last_date in FAC_dict.items():\n",
    "    two_weeks_later = last_date + np.timedelta64(2, 'W')\n",
    "    dates = list(chain.from_iterable(ends_dict[article]))   # just to be sure list is falttened\n",
    "    dates = [date for date in dates if date < two_weeks_later]\n",
    "    # print(two_weeks_later, type(dates), type(dates[0]), type(two_weeks_later))\n",
    "    #new_date = np.max(dates) if dates else last_date        \n",
    "    if dates:\n",
    "        new_date  = max(dates)\n",
    "    else:\n",
    "        new_date = last_date\n",
    "        print(f'No date (< 2W) found for article: {article}')\n",
    "    new_dict[article] = new_date\n",
    "    \n",
    "df_new = pd.DataFrame({'title' : list(new_dict.keys()), 'end_date' : list(new_dict.values())})\n",
    "df_merge = pd.merge(df_merge, df_new, on='title')\n",
    "\n",
    "df_merge.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'art_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6be63a811a07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdates\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mart_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'min:{min(dates)} max:{max(dates)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'D'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'art_dict' is not defined"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for article, dates in art_dict.items():\n",
    "    dates = np.array([np.datetime64(date) for date in dates])\n",
    "    print(f'min:{min(dates)} max:{max(dates)}')\n",
    "    p1 = dates[(dates- dates[0]) > np.timedelta64(30, 'D')]\n",
    "    p2 = dates[~((dates- dates[0]) > np.timedelta64(30, 'D'))]\n",
    "    print(article)\n",
    "    print(len(p1), len(p2))\n",
    "    if i >= 1:\n",
    "        break\n",
    "    i+=1\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(res['Belgium national football team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FAC = pd.read_csv('./data/FAC_nomination.csv', sep=';', index_col=0, parse_dates=['nomination', 'last_comment'])  \n",
    "d = df_FAC.groupby('title').count().sort_values('idx')\n",
    "len(d.loc[d.idx >= 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./res/article_dict.pkl', 'rb') as file:\n",
    "    ends_dict = pickle.load(file)\n",
    "    \n",
    "df_ends = [[i, article, set(dates)]for i, (article, dates) in enumerate(ends_dict.items())]\n",
    "df_ends = pd.DataFrame(df_ends)\n",
    "\n",
    "df_ends\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Wiki Project",
   "language": "python",
   "name": "wiki_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
